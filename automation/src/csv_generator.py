#!/usr/bin/env python3
"""
CSV Generator for SWAT+ Modular Database

This module generates the modular database CSV file from extracted parameters.
The CSV follows the existing structure with all required columns and maintains
compatibility with the current SWAT+ parameter management system.
"""

import csv
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime

try:
    from .parameter_extractor import ParameterMapping
except ImportError:
    from parameter_extractor import ParameterMapping


class CSVGenerator:
    """Generates modular database CSV from extracted parameters."""
    
    # CSV column headers matching the existing modular database structure
    CSV_HEADERS = [
        'Unique ID',
        'Broad_Classification',
        'SWAT_File',
        'database_table',
        'DATABASE_FIELD_NAME',
        'SWAT_Header_Name',
        'Text_File_Structure',
        'Position_in_File',
        'Line_in_file',
        'Swat_code type',
        'SWAT_Code_Variable_Name',
        'Description',
        'Core',
        'Units',
        'Data_Type',
        'Minimum_Range',
        'Maximum_Range',
        'Default_Value',
        'Number_Decimal_Places',
        'Primary_Key',
        'Foreign_Key',
        'Foreign_Table',
        'Foreign_Variable',
        'Doc_Path',
        'Use_in_DB',
        'Parm_Doc_Name'
    ]
    
    def __init__(self):
        """Initialize the CSV generator."""
        # Configure logging
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
    def generate_csv(
        self, 
        parameters: List[ParameterMapping], 
        output_path: Path,
        include_header: bool = True,
        include_metadata: bool = True
    ) -> bool:
        """
        Generate modular database CSV file from parameters.
        
        Args:
            parameters: List of ParameterMapping objects
            output_path: Path to output CSV file
            include_header: Whether to include CSV header row
            include_metadata: Whether to include metadata comments
            
        Returns:
            True if CSV generated successfully, False otherwise
        """
        try:
            self.logger.info(f"Generating CSV with {len(parameters)} parameters...")
            
            with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:
                writer = csv.writer(csvfile)
                
                # Write metadata comments if requested
                if include_metadata:
                    self._write_metadata(writer, len(parameters))
                
                # Write header if requested
                if include_header:
                    writer.writerow(self.CSV_HEADERS)
                
                # Write parameter rows
                for param in parameters:
                    row = self._parameter_to_csv_row(param)
                    writer.writerow(row)
            
            self.logger.info(f"Successfully generated CSV: {output_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"Error generating CSV: {e}")
            return False
    
    def _write_metadata(self, writer: csv.writer, parameter_count: int):
        """
        Write metadata comments to CSV file.
        
        Args:
            writer: CSV writer object
            parameter_count: Number of parameters in the file
        """
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        metadata_lines = [
            f"# SWAT+ Modular Database - Generated {timestamp}",
            f"# Total Parameters: {parameter_count}",
            f"# Generated by: SWAT+ Automation System",
            f"# Source: FORD-parsed Fortran code",
            "#"
        ]
        
        for line in metadata_lines:
            writer.writerow([line])
    
    def _parameter_to_csv_row(self, param: ParameterMapping) -> List[str]:
        """
        Convert a ParameterMapping to a CSV row.
        
        Args:
            param: ParameterMapping object
            
        Returns:
            List of strings representing CSV row
        """
        return [
            str(param.unique_id),
            param.broad_classification,
            param.swat_file,
            param.database_table,
            param.database_field_name,
            param.swat_header_name,
            param.text_file_structure,
            str(param.position_in_file),
            str(param.line_in_file),
            param.swat_code_type,
            param.swat_code_variable_name,
            param.description,
            param.core,
            param.units,
            param.data_type,
            param.minimum_range or '',
            param.maximum_range or '',
            param.default_value or '',
            str(param.number_decimal_places) if param.number_decimal_places else '',
            'x' if param.primary_key else '',
            param.foreign_key or '',
            param.foreign_table or '',
            param.foreign_variable or '',
            param.doc_path or '',
            param.use_in_db,
            param.parm_doc_name or ''
        ]
    
    def validate_csv_structure(self, csv_path: Path) -> Dict[str, Any]:
        """
        Validate the structure of a generated CSV file.
        
        Args:
            csv_path: Path to CSV file to validate
            
        Returns:
            Dictionary with validation results
        """
        validation_results = {
            'valid': False,
            'row_count': 0,
            'header_match': False,
            'unique_ids': True,
            'required_fields': True,
            'data_type_consistency': True,
            'errors': []
        }
        
        try:
            with open(csv_path, 'r', encoding='utf-8') as csvfile:
                # Skip metadata comments
                lines = []
                for line in csvfile:
                    if not line.strip().startswith('#'):
                        lines.append(line)
                
                # Reset file pointer and create reader
                csvfile.seek(0)
                reader = csv.reader(csvfile)
                
                # Skip metadata comments
                for row in reader:
                    if row and not row[0].startswith('#'):
                        break
                
                # Check header
                header = row if row else None
                if header:
                    validation_results['header_match'] = header == self.CSV_HEADERS
                    if not validation_results['header_match']:
                        validation_results['errors'].append("Header does not match expected structure")
                
                # Validate data rows
                unique_ids = set()
                row_count = 0
                
                for row in reader:
                    if not row or row[0].startswith('#'):
                        continue
                        
                    row_count += 1
                    
                    # Check unique ID
                    try:
                        unique_id = int(row[0])
                        if unique_id in unique_ids:
                            validation_results['unique_ids'] = False
                            validation_results['errors'].append(f"Duplicate unique ID: {unique_id}")
                        unique_ids.add(unique_id)
                    except (ValueError, IndexError):
                        validation_results['errors'].append(f"Invalid unique ID in row {row_count}")
                    
                    # Check required fields
                    required_indices = [0, 1, 2, 3, 4, 11, 14]  # Key required fields
                    for idx in required_indices:
                        if idx < len(row) and not row[idx].strip():
                            validation_results['required_fields'] = False
                            validation_results['errors'].append(f"Missing required field in row {row_count}, column {idx}")
                
                validation_results['row_count'] = row_count
                validation_results['valid'] = (
                    validation_results['header_match'] and
                    validation_results['unique_ids'] and
                    validation_results['required_fields'] and
                    row_count > 0
                )
                
        except Exception as e:
            validation_results['errors'].append(f"Error reading CSV file: {e}")
        
        return validation_results
    
    def compare_with_reference(
        self, 
        generated_csv: Path, 
        reference_csv: Path
    ) -> Dict[str, Any]:
        """
        Compare generated CSV with reference CSV file.
        
        Args:
            generated_csv: Path to generated CSV file
            reference_csv: Path to reference CSV file
            
        Returns:
            Dictionary with comparison results
        """
        comparison = {
            'identical': False,
            'row_count_diff': 0,
            'column_count_diff': 0,
            'new_parameters': [],
            'missing_parameters': [],
            'modified_parameters': [],
            'summary': {}
        }
        
        try:
            # Read both CSV files
            generated_data = self._read_csv_data(generated_csv)
            reference_data = self._read_csv_data(reference_csv)
            
            # Compare basic stats
            comparison['row_count_diff'] = len(generated_data) - len(reference_data)
            
            # Create parameter dictionaries for comparison
            gen_params = {row[0]: row for row in generated_data if row[0].isdigit()}
            ref_params = {row[0]: row for row in reference_data if row[0].isdigit()}
            
            # Find differences
            gen_ids = set(gen_params.keys())
            ref_ids = set(ref_params.keys())
            
            comparison['new_parameters'] = list(gen_ids - ref_ids)
            comparison['missing_parameters'] = list(ref_ids - gen_ids)
            
            # Check for modifications in common parameters
            common_ids = gen_ids & ref_ids
            for param_id in common_ids:
                if gen_params[param_id] != ref_params[param_id]:
                    comparison['modified_parameters'].append(param_id)
            
            # Summary
            comparison['summary'] = {
                'generated_count': len(gen_params),
                'reference_count': len(ref_params),
                'new_count': len(comparison['new_parameters']),
                'missing_count': len(comparison['missing_parameters']),
                'modified_count': len(comparison['modified_parameters'])
            }
            
            comparison['identical'] = (
                comparison['row_count_diff'] == 0 and
                len(comparison['new_parameters']) == 0 and
                len(comparison['missing_parameters']) == 0 and
                len(comparison['modified_parameters']) == 0
            )
            
        except Exception as e:
            comparison['error'] = str(e)
        
        return comparison
    
    def _read_csv_data(self, csv_path: Path) -> List[List[str]]:
        """
        Read CSV data, skipping metadata comments.
        
        Args:
            csv_path: Path to CSV file
            
        Returns:
            List of CSV rows
        """
        data = []
        
        with open(csv_path, 'r', encoding='utf-8') as csvfile:
            reader = csv.reader(csvfile)
            
            for row in reader:
                if row and not row[0].startswith('#'):
                    data.append(row)
        
        return data
    
    def generate_summary_report(self, parameters: List[ParameterMapping]) -> str:
        """
        Generate a summary report of the parameters.
        
        Args:
            parameters: List of ParameterMapping objects
            
        Returns:
            Summary report as string
        """
        if not parameters:
            return "No parameters to summarize."
        
        # Calculate statistics
        total_params = len(parameters)
        classifications = {}
        data_types = {}
        files = {}
        
        for param in parameters:
            # Count classifications
            classifications[param.broad_classification] = classifications.get(param.broad_classification, 0) + 1
            
            # Count data types
            data_types[param.data_type] = data_types.get(param.data_type, 0) + 1
            
            # Count files
            files[param.swat_file] = files.get(param.swat_file, 0) + 1
        
        # Generate report
        report_lines = [
            "SWAT+ Modular Database Summary Report",
            "=" * 50,
            f"Total Parameters: {total_params}",
            f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "Parameter Classification Distribution:",
            "-" * 40
        ]
        
        for classification, count in sorted(classifications.items()):
            percentage = (count / total_params) * 100
            report_lines.append(f"  {classification:20} : {count:4d} ({percentage:5.1f}%)")
        
        report_lines.extend([
            "",
            "Data Type Distribution:",
            "-" * 25
        ])
        
        for data_type, count in sorted(data_types.items()):
            percentage = (count / total_params) * 100
            report_lines.append(f"  {data_type:15} : {count:4d} ({percentage:5.1f}%)")
        
        report_lines.extend([
            "",
            "Top 10 Files by Parameter Count:",
            "-" * 35
        ])
        
        sorted_files = sorted(files.items(), key=lambda x: x[1], reverse=True)
        for filename, count in sorted_files[:10]:
            percentage = (count / total_params) * 100
            report_lines.append(f"  {filename:25} : {count:4d} ({percentage:5.1f}%)")
        
        return "\n".join(report_lines)


def main():
    """Command-line interface for CSV generator."""
    import argparse
    import json
    
    parser = argparse.ArgumentParser(description='Generate SWAT+ modular database CSV')
    parser.add_argument('parameters_json', help='JSON file with extracted parameters')
    parser.add_argument('output_csv', help='Output CSV file path')
    parser.add_argument('--no-header', action='store_true', help='Skip CSV header row')
    parser.add_argument('--no-metadata', action='store_true', help='Skip metadata comments')
    parser.add_argument('--validate', action='store_true', help='Validate generated CSV')
    parser.add_argument('--compare', help='Compare with reference CSV file')
    parser.add_argument('--report', help='Generate summary report file')
    
    args = parser.parse_args()
    
    # Load parameters from JSON
    try:
        with open(args.parameters_json, 'r') as f:
            param_data = json.load(f)
        
        # Convert JSON data to ParameterMapping objects
        parameters = []
        for item in param_data:
            param = ParameterMapping(
                unique_id=item['unique_id'],
                broad_classification=item['broad_classification'],
                swat_file=item['swat_file'],
                database_table=item['database_table'],
                database_field_name=item['database_field_name'],
                swat_header_name=item['database_field_name'],  # Use same name
                text_file_structure="Unique",
                position_in_file=1,
                line_in_file=1,
                swat_code_type="extracted",
                swat_code_variable_name=item['database_field_name'],
                description=item['description'],
                core="core",
                units=item['units'],
                data_type=item['data_type'],
                default_value=item.get('default_value'),
                use_in_db="x"
            )
            parameters.append(param)
            
    except Exception as e:
        print(f"Error loading parameters: {e}")
        return 1
    
    # Initialize CSV generator
    generator = CSVGenerator()
    
    # Generate CSV
    success = generator.generate_csv(
        parameters,
        Path(args.output_csv),
        include_header=not args.no_header,
        include_metadata=not args.no_metadata
    )
    
    if not success:
        print("Failed to generate CSV")
        return 1
    
    print(f"Generated CSV with {len(parameters)} parameters: {args.output_csv}")
    
    # Validate if requested
    if args.validate:
        validation = generator.validate_csv_structure(Path(args.output_csv))
        print(f"\nValidation Results:")
        print(f"  Valid: {validation['valid']}")
        print(f"  Rows: {validation['row_count']}")
        print(f"  Header match: {validation['header_match']}")
        print(f"  Unique IDs: {validation['unique_ids']}")
        print(f"  Required fields: {validation['required_fields']}")
        
        if validation['errors']:
            print(f"  Errors: {len(validation['errors'])}")
            for error in validation['errors'][:5]:  # Show first 5 errors
                print(f"    - {error}")
    
    # Compare if requested
    if args.compare:
        comparison = generator.compare_with_reference(
            Path(args.output_csv), 
            Path(args.compare)
        )
        print(f"\nComparison with {args.compare}:")
        print(f"  Identical: {comparison['identical']}")
        print(f"  Generated: {comparison['summary']['generated_count']}")
        print(f"  Reference: {comparison['summary']['reference_count']}")
        print(f"  New parameters: {comparison['summary']['new_count']}")
        print(f"  Missing parameters: {comparison['summary']['missing_count']}")
        print(f"  Modified parameters: {comparison['summary']['modified_count']}")
    
    # Generate report if requested
    if args.report:
        report = generator.generate_summary_report(parameters)
        with open(args.report, 'w') as f:
            f.write(report)
        print(f"Generated summary report: {args.report}")
    
    return 0


if __name__ == '__main__':
    exit(main())